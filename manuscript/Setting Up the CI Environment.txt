# Setting up the CI Environment

## Testing our application

Our application comes with a nice set of tests. I had to fix some minor issues
that I found running the tests, so you should be able to run them with
no problems.

It's important to always use `RAILS_ENV=test` when running the test suite.
That's because the phusion passenger image overrides this variable using the one
you pass when you run the container. Therefore, in development, it's
always going to be development environment, even if you declare you want
to use the test environment in your test helper. 

With that being said, you can run the test suite by using:

    RAILS_ENV=test rake

Output:

    root@8114b51c8ae3:/home/app/webapp# RAILS_ENV=test rake
    Run options: --seed 36129

    # Running:

    .......................................

    Finished in 4.600963s, 8.4765 runs/s, 19.9958 assertions/s.

    39 runs, 92 assertions, 0 failures, 0 errors, 0 skips

## Installing Docker

Our CI environment will be powered by Jenkins. We'll use this tool for building
our testing and production images, pushing the production image to DockerHub
and finally to ECS. We are going to use a couple of Jenkins plugins for some of these steps.

For the rest of this chapter you'll need a Jenkins environment ready (if you don't have one, you can
find a lot of tutorials out there about how to install Jenkins on EC2). I prefer to run
Jenkins in a regular server instead of containers just because I think is not necessary
to add that extra complexity (to run containers inside containers).

First we need to install docker on your Jenkins server. You can use the package manager
that comes with your Linux distribution or download the binaries from the Docker website.
In my case I'm running the Amazon Linux AMI, so I can use `yum` for installing docker:

    # yum update -y
    # yum install -y docker

Let's add the jenkins user to the docker group:

    # usermod -a -G docker jenkins

Now we can start the docker service and make it available for after rebooting:

    # service docker start
    # chkconfig docker on

## Installing the plugins

In the Jenkins plugin manager, search and install the following plugins:

    - CloudBees Docker Build and Publish plugin
    - CloudBees Docker Hub Notification
    - Github plugin

Remember to restart Jenkins after the installation is complete.

With these plugins we can pull the source code from our GitHub account, build
the Docker image and push it to DockerHub. Then, with some shell magic, we'll
update the ECS task definition and the service for our main application. This way we can
deploy to production with just a push to the master branch.

## Installing the AWS CLI

We will be sending requests to the Amazon ECS API in order to register
the updated task definition and for updating the service. We are going to need
the AWS CLI tool on the Jenkins server and add the credentials to the AWS configuration.

Once you installed the AWS CLI, run `aws configure` an add your API credentials.
You can obtain these using the web console in your AWS account.

    # sudo -su jenkins
    > aws configure

## Login to DockerHub

Jenkins also needs permission to push the images to DockerHub, so you have to
login with your DockerHub credentials using the `docker login` command:

    # docker login

## Creating the project

Go to "create new Job" and select Freestyle project. Choose a name for your project.

![Jenkins Freestyle project](images/freestyle-project.png)

Next, in the project configuration, add the URL of the GitHub repository
that contains the project:

![GitHub Repo configuration](images/jenkins-config-1.png)

Under the Source Code Management Section, select git and add your credentials.
Use the branch that you want to deploy:

![GitHub Repo configuration 2](images/jenkins-config-2.png)

In the Build Triggers section, select "Build when a change is pushed to GitHub"

![Jenkins configuration](images/jenkins-config-3.png)

In the Build section, select Docker Build And Publish and use these parameters:

![Docker Build And Publish](images/jenkins-config-4.png)

Remember to change the username of the DockerHub repository.

This docker build doesn't need to be pushed since it's going to be just for running the
test suite. If the tests pass, then we build the image that's going to
be pushed to DockerHub and finally to ECS.

## Running the tests

Add another build step, but this time select "Execute Shell" and add the following
command:

![Shell command](images/jenkins-config-5.png)

This will execute a file that's in the deploy folder. Let's inspect
the script:

    #!/bin/bash
    docker pull mysql:5.7
    docker pull elasticsearch
    docker pull redis
    docker run --name mysql -e MYSQL_ROOT_PASSWORD=secretpassword -d mysql:5.7
    docker run --name elasticsearch -d elasticsearch
    docker run --name redis -d redis

    sleep 15s
    docker run --name searchapp-test -e PASSENGER_APP_ENV=test --link mysql:db --link elasticsearch:es --link redis:redis --entrypoint="./deploy/run_tests.sh" -t yourusername/searchapp:test_v_${BUILD_NUMBER} | perl -pe '/Tests failed./ && `echo -n "Tests failed" > tests-failed-flag`'
    if [ ! -f tests-failed-flag ]; then
      echo -e "Tests passed."
    else
      echo -e "Build failed since tests failed."
      rm tests-failed-flag
      echo 'removing test containers'
      docker rm -f searchapp-test
      docker rm -f mysql
      docker rm -f elasticsearch
      docker rm -f redis
      exit 1
    fi
    echo 'removing test containers'
    docker rm -f searchapp-test
    docker rm -f mysql
    docker rm -f elasticsearch
    docker rm -f redis

This command sequence is actually pretty simple. First we pull the necessary
dependencies for the test suite, which are mysql, elasticsearch and redis.
Then we run containers for each one of these dependencies.
The sleep command is just for giving the containers some time to start before
we can link them with our application. Then we run our application with the source code that
was previously pulled from the GitHub repository. We pass the phusion passenger
environment variable and create links with the other containers. We also
pass a custom `entrypoint` which is just a simple script for setting up the test database and 
running the tests. The script also outputs the exit code so we can know if the tests failed or not.

    #!/bin/bash
    echo 'creating test database...'
    RAILS_ENV=test rake db:create
    echo 'migrating test database...'
    RAILS_ENV=test rake db:migrate
    echo 'running tests...'
    RAILS_ENV=test rake

    return_code=$?
    if [[ $return_code != 0 ]] ; then
      echo -e "Tests failed."
      exit $return_code
    fi


Click apply and save.

Now if you build the project and inspect the console output you'll see that Jenkins
is pulling the code from GitHub, building the searchapp-test image and
running the script. 

Finally you should see something like this in your console output for the build:

![Test results](images/test-results.png)

Great!, This means the shell build step will block or allow the CI pipeline to continue
depending on the test results. 
Now we have to create a new step for build the image that will be pushed
to DockerHub.

## Pushing to DockerHub

Same way as before, in the configuration of the project, add a new Docker build
and publish step but this time don't skip the push. 

![Pushing to DockerHub](images/pushing-to-dockerhub.png)

Now, create another execute shell build step and add the following line:

    ./deploy/update_service.sh

![Shell command](images/jenkins-config-6.png)

This is the most important step. The `update_service` script is going to
update the task definition adding the newly created image for our application.
Jenkins will build a new image and add a new tag using he `BUILD_NUMBER` parameter.
So every time we deploy a new version, we'll have a new image with a new tag.
This image is then pushed to DockerHub and the script will replace the old
tag with the new tag and update the revision of the task definition.
The script looks like this:


    #!/bin/bash
    SERVICE_NAME="searchapp-service"
    IMAGE_VERSION="v_"${BUILD_NUMBER}
    TASK_FAMILY="searchapp"

    # Create a new task definition for this build
    sed -e "s;%BUILD_NUMBER%;${BUILD_NUMBER};g" deploy/task-definitions/searchapp_jenkins_template.json > searchapp-v_${BUILD_NUMBER}.json
    aws ecs register-task-definition --family searchapp --cli-input-json file://searchapp-v_${BUILD_NUMBER}.json

    # Update the service with the new task definition and desired count
    TASK_REVISION=`aws ecs describe-task-definition --task-definition searchapp | egrep "revision" | tr "/" " " | awk '{print $2}' | sed 's/"$//'`
    DESIRED_COUNT=`aws ecs describe-services --cluster searchapp --services ${SERVICE_NAME} | egrep -m 1 "desiredCount" | tr "/" " " | awk '{print $2}' | sed 's/,$//'`
    if [ ${DESIRED_COUNT} = "0" ]; then
	DESIRED_COUNT="1"
    fi

    aws ecs update-service --cluster searchapp --service ${SERVICE_NAME} --task-definition ${TASK_FAMILY}:${TASK_REVISION} --desired-count ${DESIRED_COUNT}

We have a json skeleton named `searchapp_jenkins_template.json` for our task definition.
This skeleton is similar to the original task definition but with a difference on the following line:

    "image": "yourusername/searchapp:v_%BUILD_NUMBER%",

As you can see, the tag for the image has a variable that the script is replacing
with the new tag. This way we can update the task definition by adding the new
image. The script then updates the service that runs the task by passing the new
task definition.

Finally we just need a build step for cleaning up the old images. If you don't add
this step, you'll ended up with a lot of unused images on your Jenkins server.
Add the following line in a shell execution step:

    ./deploy/clean_images.sh

![Clean images](images/jenkins-config-7.png)

And click apply and save.
This script adds a couple of docker commands for removing the old test and production images
that use the previous BUILD_NUMBER as a tag:

    #!/bin/bash
    echo 'Removing previous images'
    docker rmi yourusername/searchapp:v_$((${BUILD_NUMBER}-1))
    docker rmi yourusername/searchapp:test_v_$((${BUILD_NUMBER}-1))


## Adding another EC2 instance

Right now we have a cluster with two t2.micro EC2 instances. We are
going to need one more. So let's run our command for creating another
instance. Remember to use your security group and subnet ids:

    $ aws ec2 run-instances --image-id ami-4fe4852a --count 1 --instance-type t2.micro --key-name ClusterKeyPair --security-group-ids sg-c70ff2a1 --subnet-id subnet-39706b4e  --iam-instance-profile Arn=arn:aws:iam::387705308362:instance-profile/ecsInstanceRole --associate-public-ip-address --user-data file://user-data/user-data.sh

Once the instance is ready, you should see that you have 3 instances
registered in the cluster:

    $ aws ecs describe-clusters --cluster searchapp

Output:

    {
	"clusters": [
	    {
		"status": "ACTIVE",
		"clusterName": "searchapp",
		"registeredContainerInstancesCount": 3,
		"pendingTasksCount": 0,
		"runningTasksCount": 5,
		"activeServicesCount": 5,
		"clusterArn": "arn:aws:ecs:us-east-1:387705308362:cluster/searchapp"
	    }
	],
	"failures": []
    }

One thing to notice, is that once the third instance is ready for the cluster,
the scheduler will probably move some tasks between the instances.
This happens because we have 2 instances being heavily used.
So maybe your MySQL service, or your elasticsearch service will be relocated on the new instance. 
This is a big problem, since those are services running tasks that need a volume for persisting their data.
Unfortunately, right now is not possible to sync the data between instances, and
as far as I know, is not possible to create services associated to an instance.

In my case, once I launched the third instance, my elasticsearch task was relocated
and I had to to run the rake task for indexing the data again.

If you build the Jenkins project, and inspect the console output, everything should be OK
and the application should be deployed into the cluster.

## A word on Blue-Green deployment

One of the reasons that we had to add one more instance to our cluster, was because
of how ECS launches new updated services. 
ECS uses a style of deployment known as [Blue-Green deployment](http://martinfowler.com/bliki/BlueGreenDeployment.html)
in which the new application is launched without removing the old version. 
This way if something goes wrong in the deployment, in ECS words, the ELB
can't reach the health check successfully, you are not going to have downtime, since the old
version will still be there attached to the ELB.
This is great, it gives you more security for launching new releases, but of course
it brings some difficulties.
First, we are running services attached to fixed ports, which means
you can't run more than one copy of the same service in the same instance, and
since the new and old releases will be running together for some time, you'll always
going to need an instance with that port free. So for example, if you have only one application
that runs in the port 80, you'll need at least `n+1` instances running, with `n` being the number
of tasks that are running the application.
In our case we are using 3 instances not because of this, but because of the resources
that we need (memory, cpu units). Remember that we have 5 services running, and some of them
use a big amount of resources.

## Adding a GitHub hook

The only thing we need to complete the pipeline, is to add a service hook
so we can trigger deploys by pushing to our GitHub repository. This way
the deploy will be completely automatized.

This is pretty easy, first, go to your GitHub project repository. Then go to
settings, and select  Webhook & Services.

![GitHub Hook](images/github-webhook.png)

Search for "Jenkins (GitHub plugin)" and add the following line
replacing the host with your jenkins host:

    http://[JENKINS_HOST]/github-webhook/

And click add service.

Now every time you push a change to the master branch, a new build will be triggered
for that project in Jenkins.
